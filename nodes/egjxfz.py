from typing import Tuple, Dict, Any
import torch
from PIL import Image
import numpy as np
from torchvision import transforms


def tensor2pil(image):
    return Image.fromarray(np.clip(255. * image.cpu().numpy().squeeze(), 0, 255).astype(np.uint8))


def pil2tensor(image):
    return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)


class EGJXFZNODE:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "è¾“å…¥å›¾åƒ": ("IMAGE",),
                "æ–¹å‘": (["æ°´å¹³", "å‚ç›´"],),
            },
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("å›¾åƒ",)
    FUNCTION = "image_flip"
    CATEGORY = "2ğŸ•/å›¾åƒ"

    def image_flip(self, è¾“å…¥å›¾åƒ, æ–¹å‘):
        batch_tensor = []
        for image in è¾“å…¥å›¾åƒ:
            image = tensor2pil(image)
            if æ–¹å‘ == 'æ°´å¹³':
                image = image.transpose(Image.FLIP_LEFT_RIGHT)
            elif æ–¹å‘ == 'å‚ç›´':
                image = image.transpose(Image.FLIP_TOP_BOTTOM)
            batch_tensor.append(pil2tensor(image))
        batch_tensor = torch.cat(batch_tensor, dim=0)
        return (batch_tensor, )






# æœ¬å¥—æ’ä»¶ç‰ˆæƒæ‰€å±Bç«™@çµä»™å„¿å’ŒäºŒç‹—å­ï¼Œä»…ä¾›å­¦ä¹ äº¤æµä½¿ç”¨ï¼Œæœªç»æˆæƒç¦æ­¢ä¸€åˆ‡å•†ä¸šæ€§è´¨ä½¿ç”¨
