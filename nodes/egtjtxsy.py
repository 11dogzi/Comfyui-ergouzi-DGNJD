import os
import numpy as np
import torch
import sys
from PIL import Image, ImageOps
from torchvision import transforms as T
from torchvision.transforms import functional as TF




my_dir = os.path.dirname(os.path.abspath(__file__))
custom_nodes_dir = os.path.abspath(os.path.join(my_dir, '.'))
comfy_dir = os.path.abspath(os.path.join(my_dir, '..'))
sys.path.append(comfy_dir)

from nodes import MAX_RESOLUTION


def tensor2pil(image: torch.Tensor) -> Image.Image:
    return Image.fromarray(np.clip(255. * image.cpu().numpy().squeeze(), 0, 255).astype(np.uint8))


def pil2tensor(image: Image.Image) -> torch.Tensor:
    return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)

def common_upscale(samples, ç¼©æ”¾å®½åº¦, ç¼©æ”¾é«˜åº¦, upscale_method, crop):
        if crop == "center":
            old_ç¼©æ”¾å®½åº¦ = samples.shape[3]
            old_ç¼©æ”¾é«˜åº¦ = samples.shape[2]
            old_aspect = old_ç¼©æ”¾å®½åº¦ / old_ç¼©æ”¾é«˜åº¦
            new_aspect = ç¼©æ”¾å®½åº¦ / ç¼©æ”¾é«˜åº¦
            x = 0
            y = 0
            if old_aspect > new_aspect:
                x = round((old_ç¼©æ”¾å®½åº¦ - old_ç¼©æ”¾å®½åº¦ * (new_aspect / old_aspect)) / 2)
            elif old_aspect < new_aspect:
                y = round((old_ç¼©æ”¾é«˜åº¦ - old_ç¼©æ”¾é«˜åº¦ * (old_aspect / new_aspect)) / 2)
            s = samples[:,:,y:old_ç¼©æ”¾é«˜åº¦-y,x:old_ç¼©æ”¾å®½åº¦-x]
        else:
            s = samples

        if upscale_method == "bislerp":
            return bislerp(s, ç¼©æ”¾å®½åº¦, ç¼©æ”¾é«˜åº¦)
        elif upscale_method == "lanczos":
            return lanczos(s, ç¼©æ”¾å®½åº¦, ç¼©æ”¾é«˜åº¦)
        else:
            return torch.nn.functional.interpolate(s, size=(ç¼©æ”¾é«˜åº¦, ç¼©æ”¾å®½åº¦), mode=upscale_method)


class EGCPSYTJNode:

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "è¾“å…¥åŽŸå›¾": ("IMAGE",),
                "è¾“å…¥æ°´å°": ("IMAGE",),
                "ç¼©æ”¾æ¨¡å¼": (["None", "ä¿æŒæ¯”ä¾‹é“ºæ»¡", "æŒ‰ç…§ç¼©æ”¾å€æ•°ç¼©æ”¾", "æŒ‰ç…§è¾“å…¥å®½é«˜ç¼©æ”¾"],),
                "ç¼©æ”¾æ–¹æ³•": (["nearest-exact", "bilinear", "area"],),
                "ç¼©æ”¾å€æ•°": ("FLOAT", {"default": 1, "min": 0.01, "max": 16.0, "step": 0.1}),
                "ç¼©æ”¾å®½åº¦": ("INT", {"default": 512, "min": 0, "max": MAX_RESOLUTION, "step": 64}),
                "ç¼©æ”¾é«˜åº¦": ("INT", {"default": 512, "min": 0, "max": MAX_RESOLUTION, "step": 64}),
                "åˆå§‹ä½ç½®": (["å±…ä¸­", "ä¸Š", "ä¸‹", "å·¦", "å³", "ä¸Š å·¦", "ä¸Š å³", "ä¸‹ å·¦", "ä¸‹ å³"],),
                "æ¨ªå‘ä½ç§»": ("INT", {"default": 0, "min": -48000, "max": 48000, "step": 10}),
                "ç«–å‘ä½ç§»": ("INT", {"default": 0, "min": -48000, "max": 48000, "step": 10}),
                "æ—‹è½¬åº¦æ•°": ("INT", {"default": 0, "min": -180, "max": 180, "step": 5}),
                "æ°´å°é€æ˜Žåº¦": ("FLOAT", {"default": 0, "min": 0, "max": 100, "step": 5, "display": "slider"}),
            },
            "optional": {"æ°´å°é®ç½©": ("MASK",),}
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "apply_è¾“å…¥æ°´å°"
    CATEGORY = "2ðŸ•/æ°´å°å¤§å¸ˆ"

    def apply_è¾“å…¥æ°´å°(self, è¾“å…¥åŽŸå›¾, è¾“å…¥æ°´å°, ç¼©æ”¾æ¨¡å¼, ç¼©æ”¾æ–¹æ³•, ç¼©æ”¾å€æ•°,
                            ç¼©æ”¾å®½åº¦, ç¼©æ”¾é«˜åº¦, æ¨ªå‘ä½ç§», ç«–å‘ä½ç§», æ—‹è½¬åº¦æ•°, æ°´å°é€æ˜Žåº¦, åˆå§‹ä½ç½®, æ°´å°é®ç½©=None):

        
        size = ç¼©æ”¾å®½åº¦, ç¼©æ”¾é«˜åº¦
        location = æ¨ªå‘ä½ç§», ç«–å‘ä½ç§»
        mask = æ°´å°é®ç½©

        
        if ç¼©æ”¾æ¨¡å¼ != "None":
            
            è¾“å…¥æ°´å°_size = è¾“å…¥æ°´å°.size()
            è¾“å…¥æ°´å°_size = (è¾“å…¥æ°´å°_size[2], è¾“å…¥æ°´å°_size[1])
            if ç¼©æ”¾æ¨¡å¼ == "ä¿æŒæ¯”ä¾‹é“ºæ»¡":
                h_ratio = è¾“å…¥åŽŸå›¾.size()[1] / è¾“å…¥æ°´å°_size[1]
                w_ratio = è¾“å…¥åŽŸå›¾.size()[2] / è¾“å…¥æ°´å°_size[0]
                ratio = min(h_ratio, w_ratio)
                è¾“å…¥æ°´å°_size = tuple(round(dimension * ratio) for dimension in è¾“å…¥æ°´å°_size)
            elif ç¼©æ”¾æ¨¡å¼ == "æŒ‰ç…§ç¼©æ”¾å€æ•°ç¼©æ”¾":
                è¾“å…¥æ°´å°_size = tuple(int(dimension * ç¼©æ”¾å€æ•°) for dimension in è¾“å…¥æ°´å°_size)
            elif ç¼©æ”¾æ¨¡å¼ == "æŒ‰ç…§è¾“å…¥å®½é«˜ç¼©æ”¾":
                è¾“å…¥æ°´å°_size = (size[0], size[1])

            samples = è¾“å…¥æ°´å°.movedim(-1, 1)
            è¾“å…¥æ°´å° =common_upscale(samples, è¾“å…¥æ°´å°_size[0], è¾“å…¥æ°´å°_size[1], ç¼©æ”¾æ–¹æ³•, False)
            è¾“å…¥æ°´å° = è¾“å…¥æ°´å°.movedim(1, -1)
            
        è¾“å…¥æ°´å° = tensor2pil(è¾“å…¥æ°´å°)

         
        è¾“å…¥æ°´å° = è¾“å…¥æ°´å°.convert('RGBA')
        è¾“å…¥æ°´å°.putalpha(Image.new("L", è¾“å…¥æ°´å°.size, 255))

        
        if mask is not None:
            
            mask = tensor2pil(mask)
            mask = mask.resize(è¾“å…¥æ°´å°.size)
            
            è¾“å…¥æ°´å°.putalpha(ImageOps.invert(mask))

        
        è¾“å…¥æ°´å° = è¾“å…¥æ°´å°.rotate(æ—‹è½¬åº¦æ•°, expand=True)

        
        r, g, b, a = è¾“å…¥æ°´å°.split()
        a = a.point(lambda x: max(0, int(x * (1 - æ°´å°é€æ˜Žåº¦ / 100))))
        è¾“å…¥æ°´å°.putalpha(a)  
        
        è¾“å…¥åŽŸå›¾_ç¼©æ”¾å®½åº¦, è¾“å…¥åŽŸå›¾_ç¼©æ”¾é«˜åº¦ = è¾“å…¥åŽŸå›¾.size()[2], è¾“å…¥åŽŸå›¾.size()[1]
        è¾“å…¥æ°´å°_ç¼©æ”¾å®½åº¦, è¾“å…¥æ°´å°_ç¼©æ”¾é«˜åº¦ = è¾“å…¥æ°´å°.size
        
        
        æ¨ªå‘ä½ç§»_int = None
        ç«–å‘ä½ç§»_int = None
        
        if åˆå§‹ä½ç½® == "å±…ä¸­":
            æ¨ªå‘ä½ç§»_int = int(æ¨ªå‘ä½ç§» + (è¾“å…¥åŽŸå›¾_ç¼©æ”¾å®½åº¦ - è¾“å…¥æ°´å°_ç¼©æ”¾å®½åº¦) / 2)
            ç«–å‘ä½ç§»_int = int(ç«–å‘ä½ç§» + (è¾“å…¥åŽŸå›¾_ç¼©æ”¾é«˜åº¦ - è¾“å…¥æ°´å°_ç¼©æ”¾é«˜åº¦) / 2)
        elif åˆå§‹ä½ç½® == "ä¸Š":
            æ¨ªå‘ä½ç§»_int = int(æ¨ªå‘ä½ç§» + (è¾“å…¥åŽŸå›¾_ç¼©æ”¾å®½åº¦ - è¾“å…¥æ°´å°_ç¼©æ”¾å®½åº¦) / 2)
            ç«–å‘ä½ç§»_int = ç«–å‘ä½ç§»  
        elif åˆå§‹ä½ç½® == "ä¸‹":
            æ¨ªå‘ä½ç§»_int = int(æ¨ªå‘ä½ç§» + (è¾“å…¥åŽŸå›¾_ç¼©æ”¾å®½åº¦ - è¾“å…¥æ°´å°_ç¼©æ”¾å®½åº¦) / 2)
            ç«–å‘ä½ç§»_int = int(ç«–å‘ä½ç§» + è¾“å…¥åŽŸå›¾_ç¼©æ”¾é«˜åº¦ - è¾“å…¥æ°´å°_ç¼©æ”¾é«˜åº¦)
        elif åˆå§‹ä½ç½® == "å·¦":
            ç«–å‘ä½ç§»_int = int(ç«–å‘ä½ç§» + (è¾“å…¥åŽŸå›¾_ç¼©æ”¾é«˜åº¦ - è¾“å…¥æ°´å°_ç¼©æ”¾é«˜åº¦) / 2)
            æ¨ªå‘ä½ç§»_int = æ¨ªå‘ä½ç§»  
        elif åˆå§‹ä½ç½® == "å³":
            æ¨ªå‘ä½ç§»_int = int(æ¨ªå‘ä½ç§» + è¾“å…¥åŽŸå›¾_ç¼©æ”¾å®½åº¦ - è¾“å…¥æ°´å°_ç¼©æ”¾å®½åº¦)
            ç«–å‘ä½ç§»_int = int(ç«–å‘ä½ç§» + (è¾“å…¥åŽŸå›¾_ç¼©æ”¾é«˜åº¦ - è¾“å…¥æ°´å°_ç¼©æ”¾é«˜åº¦) / 2)
        elif åˆå§‹ä½ç½® == "ä¸Š å·¦":
            pass  
        elif åˆå§‹ä½ç½® == "ä¸Š å³":
            æ¨ªå‘ä½ç§»_int = int(è¾“å…¥åŽŸå›¾_ç¼©æ”¾å®½åº¦ - è¾“å…¥æ°´å°_ç¼©æ”¾å®½åº¦ + æ¨ªå‘ä½ç§»)  
            ç«–å‘ä½ç§»_int = ç«–å‘ä½ç§»  
        elif åˆå§‹ä½ç½® == "ä¸‹ å·¦":
            æ¨ªå‘ä½ç§»_int = æ¨ªå‘ä½ç§»  
            ç«–å‘ä½ç§»_int = int(è¾“å…¥åŽŸå›¾_ç¼©æ”¾é«˜åº¦ - è¾“å…¥æ°´å°_ç¼©æ”¾é«˜åº¦ + ç«–å‘ä½ç§») 
        elif åˆå§‹ä½ç½® == "ä¸‹ å³":
            æ¨ªå‘ä½ç§»_int = int(æ¨ªå‘ä½ç§» + è¾“å…¥åŽŸå›¾_ç¼©æ”¾å®½åº¦ - è¾“å…¥æ°´å°_ç¼©æ”¾å®½åº¦)
            ç«–å‘ä½ç§»_int = int(ç«–å‘ä½ç§» + è¾“å…¥åŽŸå›¾_ç¼©æ”¾é«˜åº¦ - è¾“å…¥æ°´å°_ç¼©æ”¾é«˜åº¦)
        
        if æ¨ªå‘ä½ç§»_int is not None and ç«–å‘ä½ç§»_int is not None:
            
            location = æ¨ªå‘ä½ç§»_int, ç«–å‘ä½ç§»_int
        else:
            
            location = æ¨ªå‘ä½ç§», ç«–å‘ä½ç§»

        
        è¾“å…¥åŽŸå›¾_list = torch.unbind(è¾“å…¥åŽŸå›¾, dim=0)

        
        processed_è¾“å…¥åŽŸå›¾_list = []
        for tensor in è¾“å…¥åŽŸå›¾_list:
            
            image = tensor2pil(tensor)

            
            if mask is None:
                image.paste(è¾“å…¥æ°´å°, location)
            else:
                image.paste(è¾“å…¥æ°´å°, location, è¾“å…¥æ°´å°)

            
            processed_tensor = pil2tensor(image)

            
            processed_è¾“å…¥åŽŸå›¾_list.append(processed_tensor)

        
        è¾“å…¥åŽŸå›¾ = torch.stack([tensor.squeeze() for tensor in processed_è¾“å…¥åŽŸå›¾_list])

        
        return (è¾“å…¥åŽŸå›¾,)

# æœ¬å¥—æ’ä»¶ç‰ˆæƒæ‰€å±žBç«™@çµä»™å„¿å’ŒäºŒç‹—å­ï¼Œä»…ä¾›å­¦ä¹ äº¤æµä½¿ç”¨ï¼Œæœªç»æŽˆæƒç¦æ­¢ä¸€åˆ‡å•†ä¸šæ€§è´¨ä½¿ç”¨
