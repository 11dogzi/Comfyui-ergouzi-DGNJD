import torch
class Args:
    def __init__(self):
        self.gpu_only = False
args = Args()
def intermediate_device():
    if args.gpu_only:
        return get_torch_device()
    else:
        return torch.device("cpu")
class EGKLATENT:
    é€‰æ‹©æ¯”ä¾‹s = {
        "1:1": (1, 1),
        "3:2": (3, 2),
        "16:9": (16, 9),
        "2:3": (2, 3),
        "9:16": (9, 16)
    }

    def __init__(self):
        self.device = intermediate_device()

    @classmethod
    def INPUT_TYPES(s):
        return {"required": {"width": ("INT", {"default": 512, "min": 16, "max": 4096, "step": 8}),
                             "height": ("INT", {"default": 512, "min": 16, "max": 4096, "step": 8}),
                             "æ‰¹æ¬¡": ("INT", {"default": 1, "min": 1, "max": 4096}),
                             "é€‰æ‹©æ¯”ä¾‹": (list(s.é€‰æ‹©æ¯”ä¾‹s.keys()), {"default": "1:1"}),
                             "å¯ç”¨æ¯”ä¾‹": ("BOOLEAN", {"default": False})
                             }}

    RETURN_TYPES = ("LATENT", "INT", "INT")
    RETURN_NAMES = ('LATENT', 'width', 'height')
    FUNCTION = "generate"
    CATEGORY = "2ğŸ•/Latent"

    def generate(self, width, height, æ‰¹æ¬¡=1, é€‰æ‹©æ¯”ä¾‹="1:1", å¯ç”¨æ¯”ä¾‹=False):
        if é€‰æ‹©æ¯”ä¾‹ not in self.é€‰æ‹©æ¯”ä¾‹s.keys():
            raise ValueError(f"Invalid é€‰æ‹©æ¯”ä¾‹ value: {é€‰æ‹©æ¯”ä¾‹}. Valid é€‰æ‹©æ¯”ä¾‹s are: {', '.join(self.é€‰æ‹©æ¯”ä¾‹s.keys())}")
        if not å¯ç”¨æ¯”ä¾‹:
            latent = torch.zeros([æ‰¹æ¬¡, 4, int(height // 8), int(width // 8)], device=self.device)
            return ({"samples": latent}, width, height)
        if width == height:
            max_dim = width
            é€‰æ‹©æ¯”ä¾‹_width, é€‰æ‹©æ¯”ä¾‹_height = self.é€‰æ‹©æ¯”ä¾‹s[é€‰æ‹©æ¯”ä¾‹]
            if é€‰æ‹©æ¯”ä¾‹_width >= é€‰æ‹©æ¯”ä¾‹_height:
                width = max_dim
                height = int(max_dim * é€‰æ‹©æ¯”ä¾‹_height / é€‰æ‹©æ¯”ä¾‹_width)
            else:
                height = max_dim
                width = int(max_dim * é€‰æ‹©æ¯”ä¾‹_width / é€‰æ‹©æ¯”ä¾‹_height)
        else:
            max_dim = max(width, height)
            é€‰æ‹©æ¯”ä¾‹_width, é€‰æ‹©æ¯”ä¾‹_height = self.é€‰æ‹©æ¯”ä¾‹s[é€‰æ‹©æ¯”ä¾‹]
            if width == max_dim:
                new_height = int(max_dim * é€‰æ‹©æ¯”ä¾‹_height / é€‰æ‹©æ¯”ä¾‹_width)
                height = new_height
            elif height == max_dim:
                new_width = int(max_dim * é€‰æ‹©æ¯”ä¾‹_width / é€‰æ‹©æ¯”ä¾‹_height)
                width = new_width

        latent = torch.zeros([æ‰¹æ¬¡, 4, int(height // 8), int(width // 8)], device=self.device)
        return ({"samples": latent}, width, height)

# æœ¬å¥—æ’ä»¶ç‰ˆæƒæ‰€å±Bç«™@çµä»™å„¿å’ŒäºŒç‹—å­ï¼Œä»…ä¾›å­¦ä¹ äº¤æµä½¿ç”¨ï¼Œæœªç»æˆæƒç¦æ­¢ä¸€åˆ‡å•†ä¸šæ€§è´¨ä½¿ç”¨
