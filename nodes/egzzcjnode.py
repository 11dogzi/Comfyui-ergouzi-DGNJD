from typing import Tuple, Dict, Any
import torch
from PIL import Image
import numpy as np
from torchvision import transforms


def tensor2pil(image):
    return Image.fromarray(np.clip(255. * image.cpu().numpy().squeeze(), 0, 255).astype(np.uint8))


def pil2tensor(image):
    return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)


class EGTXZZCJNode:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "è¾“å…¥å›¾åƒ": ("IMAGE",),
                "è¾“å…¥é®ç½©": ("MASK",),  
            },
            "optional": {
                "ä¸Š": ("INT", {"default": 0, "min": 0}),
                "ä¸‹": ("INT", {"default": 0, "min": 0}),
                "å·¦": ("INT", {"default": 0, "min": 0}),
                "å³": ("INT", {"default": 0, "min": 0}),
            },
        }

    RETURN_TYPES = ("IMAGE", "MASK", "COORDS")
    RETURN_NAMES = ("è£å‰ªå›¾åƒ", "è£å‰ªé®ç½©", "è£å‰ªæ•°æ®")
    FUNCTION = "mask_crop"
    CATEGORY = "2ğŸ•/é®ç½©/ç»†åŒ–å¤„ç†"

    def mask_crop(self, è¾“å…¥å›¾åƒ, è¾“å…¥é®ç½©, ä¸Š=0, ä¸‹=0, å·¦=0, å³=0):
        
        image_pil = tensor2pil(è¾“å…¥å›¾åƒ)
        mask_pil = tensor2pil(è¾“å…¥é®ç½©)

        
        mask_array = np.array(mask_pil) > 0

        
        coords = np.where(mask_array)
        if coords[0].size == 0 or coords[1].size == 0:
            
            return (è¾“å…¥å›¾åƒ, None, è¾“å…¥å›¾åƒ)

        x0, y0, x1, y1 = coords[1].min(), coords[0].min(), coords[1].max(), coords[0].max()

        
        x0 -= å·¦
        y0 -= ä¸Š
        x1 += å³
        y1 += ä¸‹

        
        x0 = max(x0, 0)
        y0 = max(y0, 0)
        x1 = min(x1, image_pil.width)
        y1 = min(y1, image_pil.height)

        
        cropped_image_pil = image_pil.crop((x0, y0, x1, y1))

        
        cropped_mask_pil = mask_pil.crop((x0, y0, x1, y1))

        
        cropped_image_tensor = pil2tensor(cropped_image_pil)
        cropped_mask_tensor = pil2tensor(cropped_mask_pil)

        
        return (cropped_image_tensor, cropped_mask_tensor, (y0, y1, x0, x1))





# æœ¬å¥—æ’ä»¶ç‰ˆæƒæ‰€å±Bç«™@çµä»™å„¿å’ŒäºŒç‹—å­ï¼Œä»…ä¾›å­¦ä¹ äº¤æµä½¿ç”¨ï¼Œæœªç»æˆæƒç¦æ­¢ä¸€åˆ‡å•†ä¸šæ€§è´¨ä½¿ç”¨
