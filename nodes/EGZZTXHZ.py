import torch
from PIL import Image
import numpy as np
def tensor2pil(image):
    return Image.fromarray(np.clip(255. * image.cpu().numpy().squeeze(), 0, 255).astype(np.uint8))
def pil2tensor(image):
    return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)
def image2mask(image_pil, channel='red'):
    image_array = np.array(image_pil)
    image_tensor = torch.from_numpy(image_array).float() / 255.0
    if channel == 'red':
        mask_tensor = image_tensor[:, :, 0]
    elif channel == 'green':
        mask_tensor = image_tensor[:, :, 1]
    elif channel == 'blue':
        mask_tensor = image_tensor[:, :, 2]
    elif channel == 'alpha':
        if image_tensor.shape[2] == 4:
            mask_tensor = 1 - image_tensor[:, :, 3]
        else:
            mask_tensor = torch.zeros(image_tensor.shape[:2])
    else:
        raise ValueError("Invalid channel specified.")
    mask_array = mask_tensor.numpy() * 255
    mask_array = mask_array.astype(np.uint8)
    mask_pil = Image.fromarray(mask_array)
    return mask_pil
def mask2image(mask_pil):
    mask_array = np.array(mask_pil)
    mask_tensor = torch.from_numpy(mask_array).float() / 255.0
    mask_tensor = mask_tensor.unsqueeze(0).unsqueeze(0)
    result_tensor = mask_tensor.expand(-1, 3, -1, -1)
    result_array = result_tensor.squeeze().numpy() * 255
    result_array = result_array.transpose(1, 2, 0).astype(np.uint8)
    result_pil = Image.fromarray(result_array)
    return result_pil
class EGTXZZZHNode:
    def __init__(self):
        pass
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {},
            "optional": {
                "è¾“å…¥é®ç½©": ("MASK", {}),
                "è¾“å…¥å›¾åƒ": ("IMAGE", {}),
                "é€‰æ‹©é€šé“": (["red", "green", "blue", "alpha"], {"default": "red"}),
            },
        }
    RETURN_TYPES = ("IMAGE", "MASK")
    RETURN_NAMES = ("è½¬æ¢å›¾åƒ", "è½¬æ¢é®ç½©")
    FUNCTION = "convert_input"
    CATEGORY = "2ğŸ•/é®ç½©"
    def convert_input(self, è¾“å…¥å›¾åƒ=None, è¾“å…¥é®ç½©=None, é€‰æ‹©é€šé“='red'):
        if è¾“å…¥å›¾åƒ is None and è¾“å…¥é®ç½© is None:
            default_image = Image.new('L', (256, 256), color=255)
            default_mask = Image.new('L', (256, 256), color=0)
            image_tensor = pil2tensor(default_image)
            mask_tensor = pil2tensor(default_mask)
            return [image_tensor, mask_tensor]
        
        elif è¾“å…¥å›¾åƒ is not None:
            input_image_pil = tensor2pil(è¾“å…¥å›¾åƒ)
            è½¬æ¢é®ç½©_pil = image2mask(input_image_pil, é€‰æ‹©é€šé“)
            è½¬æ¢å›¾åƒ_pil = input_image_pil
        elif è¾“å…¥é®ç½© is not None:
            input_mask_pil = tensor2pil(è¾“å…¥é®ç½©)
            è½¬æ¢å›¾åƒ_pil = mask2image(input_mask_pil)
            è½¬æ¢é®ç½©_pil = input_mask_pil
        
        è½¬æ¢å›¾åƒ_tensor = pil2tensor(è½¬æ¢å›¾åƒ_pil)
        è½¬æ¢é®ç½©_tensor = pil2tensor(è½¬æ¢é®ç½©_pil)
        
        return [è½¬æ¢å›¾åƒ_tensor, è½¬æ¢é®ç½©_tensor]

# æœ¬å¥—æ’ä»¶ç‰ˆæƒæ‰€å±Bç«™@çµä»™å„¿å’ŒäºŒç‹—å­ï¼Œä»…ä¾›å­¦ä¹ äº¤æµä½¿ç”¨ï¼Œæœªç»æˆæƒç¦æ­¢ä¸€åˆ‡å•†ä¸šæ€§è´¨ä½¿ç”¨
